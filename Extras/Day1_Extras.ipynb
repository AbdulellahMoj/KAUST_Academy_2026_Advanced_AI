{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf0af9d",
   "metadata": {},
   "source": [
    "![image.png](https://i.imgur.com/a3uAqnb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3f943",
   "metadata": {},
   "source": [
    "# Day 1 - Extended Explanations & Resources\n",
    "\n",
    "This notebook contains detailed mathematical explanations, worked examples, and comprehensive resources to supplement the main Day1 notebooks.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1fb04e",
   "metadata": {},
   "source": [
    "## ğŸ§® Mathematical Understanding of Reshape Operations\n",
    "\n",
    "All these operations **preserve the total number of elements** in the tensor. This is a fundamental rule:\n",
    "\n",
    "$$\n",
    "\\text{Total Elements Before} = \\text{Total Elements After}\n",
    "$$\n",
    "\n",
    "### ğŸ“ Detailed Calculations\n",
    "\n",
    "#### 1ï¸âƒ£ **Flatten Example**\n",
    "**Before:** $(32, 3, 28, 28)$  \n",
    "**After:** $(32, 2352)$\n",
    "\n",
    "**Verification:**\n",
    "$$\n",
    "32 \\times 3 \\times 28 \\times 28 = 75,264 \\text{ elements}\n",
    "$$\n",
    "$$\n",
    "32 \\times 2352 = 75,264 \\text{ elements} \\quad âœ…\n",
    "$$\n",
    "\n",
    "Where $2352 = 3 \\times 28 \\times 28$\n",
    "\n",
    "---\n",
    "\n",
    "#### 2ï¸âƒ£ **Squeeze Example**\n",
    "**Before:** $(1, 3, 28, 28)$ - Notice the dimension of size 1  \n",
    "**After:** $(3, 28, 28)$ - Dimension removed\n",
    "\n",
    "**Verification:**\n",
    "$$\n",
    "1 \\times 3 \\times 28 \\times 28 = 2,352 \\text{ elements}\n",
    "$$\n",
    "$$\n",
    "3 \\times 28 \\times 28 = 2,352 \\text{ elements} \\quad âœ…\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3ï¸âƒ£ **Permute Example**\n",
    "**Before:** $(32, 28, 28, 3)$ - Channels last format  \n",
    "**After:** $(32, 3, 28, 28)$ - Channels first format\n",
    "\n",
    "**Verification:**\n",
    "$$\n",
    "32 \\times 28 \\times 28 \\times 3 = 75,264 \\text{ elements}\n",
    "$$\n",
    "$$\n",
    "32 \\times 3 \\times 28 \\times 28 = 75,264 \\text{ elements} \\quad âœ…\n",
    "$$\n",
    "\n",
    "**Note:** Permute only **reorders** the data, doesn't change the total count!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4bfd0",
   "metadata": {},
   "source": [
    "## ğŸ“ Mathematical Foundation of Linear Layers\n",
    "\n",
    "A **Linear (Fully Connected) layer** performs the following transformation:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{W}\\mathbf{x} + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{x} \\in \\mathbb{R}^{n_{in}}$ = Input vector (in_features)\n",
    "- $\\mathbf{W} \\in \\mathbb{R}^{n_{out} \\times n_{in}}$ = Weight matrix (learnable)\n",
    "- $\\mathbf{b} \\in \\mathbb{R}^{n_{out}}$ = Bias vector (learnable)\n",
    "- $\\mathbf{y} \\in \\mathbb{R}^{n_{out}}$ = Output vector (out_features)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§® Worked Example\n",
    "\n",
    "For `nn.Linear(in_features=5, out_features=3)`:\n",
    "\n",
    "**Step 1:** Define the shapes\n",
    "- Input: $\\mathbf{x} \\in \\mathbb{R}^{5}$ (5 features)\n",
    "- Weights: $\\mathbf{W} \\in \\mathbb{R}^{3 \\times 5}$ (3Ã—5 matrix)\n",
    "- Bias: $\\mathbf{b} \\in \\mathbb{R}^{3}$ (3 values)\n",
    "\n",
    "**Step 2:** Matrix multiplication\n",
    "$$\n",
    "\\mathbf{y} = \\underbrace{\\mathbf{W}}_{3 \\times 5} \\cdot \\underbrace{\\mathbf{x}}_{5 \\times 1} + \\underbrace{\\mathbf{b}}_{3 \\times 1} = \\underbrace{\\mathbf{y}}_{3 \\times 1}\n",
    "$$\n",
    "\n",
    "**Step 3:** For a batch of 16 samples\n",
    "$$\n",
    "\\mathbf{Y} = \\underbrace{\\mathbf{X}}_{16 \\times 5} \\cdot \\underbrace{\\mathbf{W}^T}_{5 \\times 3} + \\underbrace{\\mathbf{b}}_{1 \\times 3} = \\underbrace{\\mathbf{Y}}_{16 \\times 3}\n",
    "$$\n",
    "\n",
    "âœ… **Result:** $(16, 5) \\xrightarrow{\\text{Linear}} (16, 3)$\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¢ Parameter Count Calculation\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "\\text{Parameters} = (\\text{in\\_features} \\times \\text{out\\_features}) + \\text{out\\_features}\n",
    "$$\n",
    "\n",
    "**For our example:**\n",
    "$$\n",
    "\\text{Parameters} = (5 \\times 3) + 3 = 15 + 3 = 18\n",
    "$$\n",
    "\n",
    "**Breakdown:**\n",
    "- **Weights:** $5 \\times 3 = 15$ parameters\n",
    "- **Biases:** $3$ parameters\n",
    "- **Total:** $18$ learnable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4efd28",
   "metadata": {},
   "source": [
    "## ğŸ“ Convolution Output Size Formula Explained\n",
    "\n",
    "The **complete formula** for calculating output dimensions after a Conv2D operation is:\n",
    "\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\times \\text{padding} - \\text{dilation} \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\times \\text{padding} - \\text{dilation} \\times (\\text{kernel\\_size} - 1) - 1}{\\text{stride}} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "**Simplified formula** (when dilation=1, which is the default):\n",
    "\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\times \\text{padding} - \\text{kernel\\_size}}{\\text{stride}} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $H_{in}, W_{in}$ = Input height and width\n",
    "- $\\text{padding}$ = Number of pixels added around the border\n",
    "- $\\text{kernel\\_size}$ = Size of the convolution filter (e.g., 3Ã—3)\n",
    "- $\\text{stride}$ = Step size for moving the filter\n",
    "- $\\lfloor \\cdot \\rfloor$ = Floor function (round down)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§® Worked Example #1: No Padding\n",
    "\n",
    "**Given:**\n",
    "- Input: $(3, 32, 32)$ - RGB image 32Ã—32\n",
    "- Conv2D: `in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0`\n",
    "\n",
    "**Step 1:** Calculate output height\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{32 + 2(0) - 3}{1} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "**Step 2:** Simplify\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{29}{1} \\right\\rfloor + 1 = 29 + 1 = 30\n",
    "$$\n",
    "\n",
    "**Step 3:** Same for width\n",
    "$$\n",
    "W_{out} = 30\n",
    "$$\n",
    "\n",
    "**Step 4:** Output channels come from the layer definition\n",
    "$$\n",
    "C_{out} = 16\n",
    "$$\n",
    "\n",
    "âœ… **Final Result:** $(3, 32, 32) \\xrightarrow{\\text{Conv2D}} (16, 30, 30)$\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§® Worked Example #2: With Padding (Same Size Output)\n",
    "\n",
    "**Given:**\n",
    "- Input: $(3, 32, 32)$\n",
    "- Conv2D: `kernel_size=3, stride=1, padding=1`\n",
    "\n",
    "**Step 1:** Calculate with padding\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{32 + 2(1) - 3}{1} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "**Step 2:** Simplify\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{32 + 2 - 3}{1} \\right\\rfloor + 1 = \\left\\lfloor \\frac{31}{1} \\right\\rfloor + 1 = 32\n",
    "$$\n",
    "\n",
    "âœ… **Result:** $(32, 32) \\xrightarrow{\\text{padding=1}} (32, 32)$ - **Size preserved!**\n",
    "\n",
    "**ğŸ’¡ Pro Tip:** For `kernel_size=3` and `stride=1`, use `padding=1` to keep the same spatial dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¢ Parameter Count for Conv2D\n",
    "\n",
    "**Formula:**\n",
    "$$\n",
    "\\text{Parameters} = (\\text{kernel\\_size}^2 \\times C_{in} \\times C_{out}) + C_{out}\n",
    "$$\n",
    "\n",
    "**Example:** `Conv2d(3, 16, kernel_size=3)`\n",
    "$$\n",
    "\\text{Parameters} = (3^2 \\times 3 \\times 16) + 16 = (9 \\times 3 \\times 16) + 16 = 432 + 16 = 448\n",
    "$$\n",
    "\n",
    "**Breakdown:**\n",
    "- **Weights:** $3 \\times 3 \\times 3 \\times 16 = 432$ (kernel Ã— kernel Ã— in_channels Ã— out_channels)\n",
    "- **Biases:** $16$ (one per output channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab8504f",
   "metadata": {},
   "source": [
    "## ğŸ“ Pooling Mathematics\n",
    "\n",
    "Pooling operations **reduce spatial dimensions** while keeping the number of channels the same.\n",
    "\n",
    "### ğŸ”¹ MaxPool2d Formula\n",
    "\n",
    "For a pooling window of size $k \\times k$ with stride $s$:\n",
    "\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{H_{in} - k}{s} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_{out} = \\left\\lfloor \\frac{W_{in} - k}{s} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "**Note:** Channels remain unchanged! $C_{out} = C_{in}$\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§® Worked Example\n",
    "\n",
    "**Given:**\n",
    "- Input: $(2, 16, 32, 32)$ - Batch=2, Channels=16, Size=32Ã—32\n",
    "- MaxPool2d: `kernel_size=2, stride=2`\n",
    "\n",
    "**Step 1:** Calculate output height\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{32 - 2}{2} \\right\\rfloor + 1 = \\left\\lfloor \\frac{30}{2} \\right\\rfloor + 1 = 15 + 1 = 16\n",
    "$$\n",
    "\n",
    "**Step 2:** Calculate output width (same)\n",
    "$$\n",
    "W_{out} = 16\n",
    "$$\n",
    "\n",
    "**Step 3:** Channels stay the same\n",
    "$$\n",
    "C_{out} = 16 \\text{ (unchanged)}\n",
    "$$\n",
    "\n",
    "âœ… **Final Result:** $(2, 16, 32, 32) \\xrightarrow{\\text{MaxPool2d}} (2, 16, 16, 16)$\n",
    "\n",
    "**Spatial reduction:** $32 \\times 32 = 1024$ pixels â†’ $16 \\times 16 = 256$ pixels (75% reduction!)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ MaxPool vs AvgPool\n",
    "\n",
    "| **Operation** | **Formula** | **Use Case** |\n",
    "|--------------|-------------|------------|\n",
    "| **MaxPool** | $y_{i,j} = \\max\\limits_{(m,n) \\in \\text{window}} x_{i+m, j+n}$ | Preserves strong features (edges, corners) |\n",
    "| **AvgPool** | $y_{i,j} = \\frac{1}{k^2}\\sum\\limits_{(m,n) \\in \\text{window}} x_{i+m, j+n}$ | Smooths features, reduces noise |\n",
    "\n",
    "**MaxPool** takes the **maximum value** in each window.  \n",
    "**AvgPool** takes the **average value** in each window.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Why Pooling?\n",
    "\n",
    "1. **Reduces computation** - Fewer pixels = faster processing\n",
    "2. **Provides translation invariance** - Small shifts don't affect output much\n",
    "3. **Prevents overfitting** - Reduces parameters by reducing spatial size\n",
    "4. **Focuses on important features** - Keeps strongest activations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7584fef",
   "metadata": {},
   "source": [
    "## ğŸ§® Complete CNN Architecture Analysis\n",
    "\n",
    "Let's trace the **complete mathematical transformation** through a CNN pipeline:\n",
    "\n",
    "### ğŸ“Š Layer-by-Layer Shape Transformation\n",
    "\n",
    "**Starting Input:** $(32, 3, 32, 32)$ - Batch of 32 RGB images, 32Ã—32 pixels\n",
    "\n",
    "---\n",
    "\n",
    "**Layer 1: Conv2d(3, 16, kernel_size=3)**\n",
    "\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{32 - 3}{1} \\right\\rfloor + 1 = 30\n",
    "$$\n",
    "\n",
    "Output: $(32, 16, 30, 30)$\n",
    "\n",
    "---\n",
    "\n",
    "**Layer 2: MaxPool2d(kernel_size=2)**\n",
    "\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{30 - 2}{2} \\right\\rfloor + 1 = 15\n",
    "$$\n",
    "\n",
    "Output: $(32, 16, 15, 15)$\n",
    "\n",
    "---\n",
    "\n",
    "**Layer 3: Conv2d(16, 32, kernel_size=3)**\n",
    "\n",
    "$$\n",
    "H_{out} = \\left\\lfloor \\frac{15 - 3}{1} \\right\\rfloor + 1 = 13\n",
    "$$\n",
    "\n",
    "Output: $(32, 32, 13, 13)$\n",
    "\n",
    "---\n",
    "\n",
    "**Layer 4: Flatten**\n",
    "\n",
    "$$\n",
    "\\text{Features} = 32 \\times 13 \\times 13 = 5,408\n",
    "$$\n",
    "\n",
    "Output: $(32, 5408)$\n",
    "\n",
    "---\n",
    "\n",
    "**Layer 5: Linear(5408, 10)**\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = \\mathbf{X} \\cdot \\mathbf{W}^T + \\mathbf{b}\n",
    "$$\n",
    "\n",
    "Output: $(32, 10)$ - 10 class predictions per image\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¢ Total Parameter Count\n",
    "\n",
    "| **Layer** | **Type** | **Parameters** | **Calculation** |\n",
    "|-----------|----------|----------------|-----------------|\n",
    "| Conv1 | Conv2d(3â†’16, k=3) | 448 | $(3^2 \\times 3 \\times 16) + 16$ |\n",
    "| Conv2 | Conv2d(16â†’32, k=3) | 4,640 | $(3^2 \\times 16 \\times 32) + 32$ |\n",
    "| FC | Linear(5408â†’10) | 54,090 | $(5408 \\times 10) + 10$ |\n",
    "| **TOTAL** | | **59,178** | Sum of all parameters |\n",
    "\n",
    "**Breakdown:**\n",
    "- **Convolutional layers:** $448 + 4,640 = 5,088$ parameters (8.6%)\n",
    "- **Fully connected layer:** $54,090$ parameters (91.4%)\n",
    "\n",
    "ğŸ’¡ **Insight:** The FC layer has the most parameters! That's why modern architectures minimize FC layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807db339",
   "metadata": {},
   "source": [
    "## ğŸ“ Training Mathematics: Loss Functions & Optimization\n",
    "\n",
    "### ğŸ”¹ Cross-Entropy Loss (What We Use)\n",
    "\n",
    "For multi-class classification, we use **Cross-Entropy Loss**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ = Batch size (number of samples)\n",
    "- $C$ = Number of classes\n",
    "- $y_{i,c}$ = True label (1 if sample $i$ is class $c$, else 0)\n",
    "- $\\hat{y}_{i,c}$ = Predicted probability for class $c$\n",
    "\n",
    "**Note:** PyTorch's `CrossEntropyLoss` includes **softmax**, so you don't apply it manually!\n",
    "\n",
    "$$\n",
    "\\text{CrossEntropyLoss}(\\text{logits}, \\text{labels}) = \\text{Softmax}(\\text{logits}) + \\text{Negative Log Likelihood}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§® Loss Calculation Example\n",
    "\n",
    "**Given:**\n",
    "- True label: Class 2 (out of 3 classes)\n",
    "- Model output (logits): $[2.0, 1.0, 0.5]$\n",
    "\n",
    "**Step 1:** Apply softmax to get probabilities\n",
    "$$\n",
    "\\text{Softmax}(x_i) = \\frac{e^{x_i}}{\\sum_j e^{x_j}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\left[\\frac{e^{2.0}}{e^{2.0}+e^{1.0}+e^{0.5}}, \\frac{e^{1.0}}{e^{2.0}+e^{1.0}+e^{0.5}}, \\frac{e^{0.5}}{e^{2.0}+e^{1.0}+e^{0.5}}\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{y} \\approx [0.659, 0.242, 0.099]\n",
    "$$\n",
    "\n",
    "**Step 2:** Calculate loss (for true class 2, index 1 in 0-indexed)\n",
    "$$\n",
    "\\mathcal{L} = -\\log(\\hat{y}_2) = -\\log(0.242) \\approx 1.42\n",
    "$$\n",
    "\n",
    "**Interpretation:**\n",
    "- **Low loss** (close to 0) â†’ Model is confident and correct âœ…\n",
    "- **High loss** â†’ Model is uncertain or wrong âŒ\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Gradient Descent: Weight Update Rule\n",
    "\n",
    "**Basic Gradient Descent:**\n",
    "$$\n",
    "W_{t+1} = W_t - \\eta \\nabla_W \\mathcal{L}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $W_t$ = Weights at iteration $t$\n",
    "- $\\eta$ = Learning rate (e.g., $0.001$)\n",
    "- $\\nabla_W \\mathcal{L}$ = Gradient of loss with respect to weights\n",
    "- $W_{t+1}$ = Updated weights\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Adam Optimizer (What We Use)\n",
    "\n",
    "**Adam** (Adaptive Moment Estimation) is an advanced optimizer that adapts the learning rate:\n",
    "\n",
    "$$\n",
    "m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t \\quad \\text{(First moment - momentum)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_t = \\beta_2 v_{t-1} + (1-\\beta_2) g_t^2 \\quad \\text{(Second moment - variance)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{m}_t = \\frac{m_t}{1-\\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t}{1-\\beta_2^t} \\quad \\text{(Bias correction)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_t = W_{t-1} - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "$$\n",
    "\n",
    "**Default hyperparameters:**\n",
    "- $\\beta_1 = 0.9$ (momentum)\n",
    "- $\\beta_2 = 0.999$ (variance)\n",
    "- $\\epsilon = 10^{-8}$ (numerical stability)\n",
    "\n",
    "**Why Adam?**\n",
    "âœ… Adapts learning rate per parameter  \n",
    "âœ… Works well with sparse gradients  \n",
    "âœ… Requires minimal tuning  \n",
    "âœ… Fast convergence  \n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”„ Backpropagation: Chain Rule\n",
    "\n",
    "**Backpropagation** computes gradients using the **chain rule**:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W^{(1)}} = \\frac{\\partial \\mathcal{L}}{\\partial y} \\cdot \\frac{\\partial y}{\\partial h} \\cdot \\frac{\\partial h}{\\partial W^{(1)}}\n",
    "$$\n",
    "\n",
    "PyTorch does this automatically when you call `.backward()`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8272f0",
   "metadata": {},
   "source": [
    "## ğŸ“ Validation Metrics: Measuring Model Performance\n",
    "\n",
    "### ğŸ”¹ Accuracy Formula\n",
    "\n",
    "**Accuracy** measures the percentage of correct predictions:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} \\times 100\\%\n",
    "$$\n",
    "\n",
    "More formally:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{1}[\\hat{y}_i = y_i] \\times 100\\%\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ = Total number of samples\n",
    "- $\\hat{y}_i$ = Predicted class for sample $i$\n",
    "- $y_i$ = True class for sample $i$\n",
    "- $\\mathbb{1}[\\cdot]$ = Indicator function (1 if true, 0 if false)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§® Worked Example\n",
    "\n",
    "**Scenario:** Testing on 10,000 images\n",
    "\n",
    "**Step 1:** Count correct predictions\n",
    "- Correctly predicted: 8,547 images\n",
    "- Incorrectly predicted: 1,453 images\n",
    "\n",
    "**Step 2:** Calculate accuracy\n",
    "$$\n",
    "\\text{Accuracy} = \\frac{8,547}{10,000} \\times 100\\% = 85.47\\%\n",
    "$$\n",
    "\n",
    "**Step 3:** Calculate error rate\n",
    "$$\n",
    "\\text{Error Rate} = 100\\% - 85.47\\% = 14.53\\%\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š Understanding Model Performance\n",
    "\n",
    "| **Metric** | **Formula** | **Good Value** | **Interpretation** |\n",
    "|------------|-------------|----------------|-------------------|\n",
    "| **Accuracy** | $\\frac{\\text{Correct}}{N} \\times 100\\%$ | > 90% | Overall correctness |\n",
    "| **Loss** | $-\\frac{1}{N}\\sum \\log(\\hat{y})$ | Close to 0 | Model confidence |\n",
    "| **Error Rate** | $100\\% - \\text{Accuracy}$ | < 10% | Misclassification rate |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Training vs Validation Performance\n",
    "\n",
    "**What to look for:**\n",
    "\n",
    "âœ… **Good Model:**\n",
    "- Train accuracy â‰ˆ Validation accuracy (both high)\n",
    "- Both improving over epochs\n",
    "\n",
    "ğŸš¨ **Overfitting:**\n",
    "- Train accuracy >> Validation accuracy\n",
    "- Train loss keeps decreasing, validation loss increases\n",
    "\n",
    "ğŸš¨ **Underfitting:**\n",
    "- Both train and validation accuracy are low\n",
    "- Model hasn't learned enough\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ˆ Example Performance Analysis\n",
    "\n",
    "**Epoch 1:**\n",
    "- Train Acc: 65%, Val Acc: 63% â†’ **Good start, similar performance**\n",
    "\n",
    "**Epoch 5:**\n",
    "- Train Acc: 92%, Val Acc: 89% â†’ **Excellent, slight gap is normal**\n",
    "\n",
    "**Epoch 10:**\n",
    "- Train Acc: 98%, Val Acc: 85% â†’ **âš ï¸ Overfitting detected!**\n",
    "\n",
    "**Solution for overfitting:**\n",
    "- Add dropout layers\n",
    "- Use data augmentation\n",
    "- Reduce model complexity\n",
    "- Stop training earlier (early stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c991b",
   "metadata": {},
   "source": [
    "\n",
    "### ğŸ¨ **Interactive Visualizations**\n",
    "\n",
    "#### Model Understanding\n",
    "- ğŸ–¥ï¸ **[CNN Explainer](https://poloclub.github.io/cnn-explainer/)** - Interactive CNN visualization\n",
    "- ğŸ® **[TensorFlow Playground](https://playground.tensorflow.org/)** - Neural network playground\n",
    "- ğŸ¨ **[ConvNet Playground](https://cs.stanford.edu/people/karpathy/convnetjs/)** - Real-time training\n",
    "- ğŸ“Š **[Netron](https://netron.app/)** - Model architecture viewer\n",
    "- ğŸ–¼ï¸ **[NN-SVG](https://alexlenail.me/NN-SVG/)** - Architecture diagram generator\n",
    "\n",
    "#### Mathematical Concepts\n",
    "- ğŸ¯ **[Convolution Arithmetic](https://github.com/vdumoulin/conv_arithmetic)** - Animated convolutions\n",
    "- ğŸ“ **[Matrix Calculus](http://www.matrixcalculus.org/)** - Automatic differentiation\n",
    "- ğŸ¨ **[Distill.pub](https://distill.pub/)** - Interactive machine learning research\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3403f8e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Contributed by: Abdulellah Mojalld\n",
    "![image.png](https://i.imgur.com/a3uAqnb.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
